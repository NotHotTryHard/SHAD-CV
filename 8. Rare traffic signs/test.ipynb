{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "root='/Users/user/Documents/programing/Python/CV/8. Rare traffic signs/tests/00_unittest_dataset_input/data_example_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_batch(batch):\n",
    "        for image, _, landmark in batch:\n",
    "        image = (image - image.min()) / (image.max() - image.min())\n",
    "\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(image.numpy().transpose((1, 2, 0)))\n",
    "        plt.label = landmark\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_example_3\n",
      "data_example_3\n",
      "data_example_3\n",
      "data_example_3\n",
      "data_example_3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/user/Documents/programing/Python/CV/8. Rare traffic signs/tests/00_unittest_dataset_input/data_example_3/4.png',\n",
       " '/Users/user/Documents/programing/Python/CV/8. Rare traffic signs/tests/00_unittest_dataset_input/data_example_3/2.png',\n",
       " '/Users/user/Documents/programing/Python/CV/8. Rare traffic signs/tests/00_unittest_dataset_input/data_example_3/3.png',\n",
       " '/Users/user/Documents/programing/Python/CV/8. Rare traffic signs/tests/00_unittest_dataset_input/data_example_3/1.png',\n",
       " '/Users/user/Documents/programing/Python/CV/8. Rare traffic signs/tests/00_unittest_dataset_input/data_example_3/0.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# Получение всех файлов с расширением .txt в папке и её подкаталогах\n",
    "files = glob.glob(f'{root}/**/*.png', recursive=True)\n",
    "for path in files:\n",
    "    print(os.path.basename(os.path.dirname(path)))\n",
    "display(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('classes.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = {class_name: data[class_name]['id'] for class_name in data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1.1': 0,\n",
       " '1.10': 1,\n",
       " '1.11.1': 2,\n",
       " '1.11.2': 3,\n",
       " '1.12.1': 4,\n",
       " '1.12.2': 5,\n",
       " '1.13': 6,\n",
       " '1.14': 7,\n",
       " '1.15': 8,\n",
       " '1.16': 9,\n",
       " '1.17': 10,\n",
       " '1.18': 11,\n",
       " '1.19': 12,\n",
       " '1.2': 13,\n",
       " '1.20.1': 14,\n",
       " '1.20.2': 15,\n",
       " '1.20.3': 16,\n",
       " '1.21': 17,\n",
       " '1.22': 18,\n",
       " '1.23': 19,\n",
       " '1.25': 20,\n",
       " '1.26': 21,\n",
       " '1.27': 22,\n",
       " '1.30': 23,\n",
       " '1.31': 24,\n",
       " '1.33': 25,\n",
       " '1.5': 26,\n",
       " '1.6': 27,\n",
       " '1.7': 28,\n",
       " '1.8': 29,\n",
       " '2.1': 30,\n",
       " '2.2': 31,\n",
       " '2.3.1': 32,\n",
       " '2.3.2': 33,\n",
       " '2.3.3': 34,\n",
       " '2.3.4': 35,\n",
       " '2.3.5': 36,\n",
       " '2.3.6': 37,\n",
       " '2.4': 38,\n",
       " '2.5': 39,\n",
       " '2.6': 40,\n",
       " '2.7': 41,\n",
       " '3.1': 42,\n",
       " '3.10': 43,\n",
       " '3.11.n13': 44,\n",
       " '3.11.n17': 45,\n",
       " '3.11.n20': 46,\n",
       " '3.11.n23': 47,\n",
       " '3.11.n5': 48,\n",
       " '3.11.n8': 49,\n",
       " '3.11.n9': 50,\n",
       " '3.12.n10': 51,\n",
       " '3.12.n3': 52,\n",
       " '3.12.n5': 53,\n",
       " '3.12.n6': 54,\n",
       " '3.13.r': 55,\n",
       " '3.13.r2.5': 56,\n",
       " '3.13.r2.6': 57,\n",
       " '3.13.r3': 58,\n",
       " '3.13.r3.3': 59,\n",
       " '3.13.r3.5': 60,\n",
       " '3.13.r3.7': 61,\n",
       " '3.13.r3.9': 62,\n",
       " '3.13.r4.0': 63,\n",
       " '3.13.r4.1': 64,\n",
       " '3.13.r4.2': 65,\n",
       " '3.13.r4.3': 66,\n",
       " '3.13.r4.5': 67,\n",
       " '3.13.r5': 68,\n",
       " '3.13.r5.2': 69,\n",
       " '3.14.r2.7': 70,\n",
       " '3.14.r3': 71,\n",
       " '3.14.r3.5': 72,\n",
       " '3.14.r3.7': 73,\n",
       " '3.16.n': 74,\n",
       " '3.16.n1': 75,\n",
       " '3.16.n3': 76,\n",
       " '3.18.1': 77,\n",
       " '3.18.2': 78,\n",
       " '3.19': 79,\n",
       " '3.2': 80,\n",
       " '3.20': 81,\n",
       " '3.21': 82,\n",
       " '3.24.n': 83,\n",
       " '3.24.n10': 84,\n",
       " '3.24.n20': 85,\n",
       " '3.24.n30': 86,\n",
       " '3.24.n40': 87,\n",
       " '3.24.n45': 88,\n",
       " '3.24.n5': 89,\n",
       " '3.24.n50': 90,\n",
       " '3.24.n60': 91,\n",
       " '3.24.n70': 92,\n",
       " '3.24.n80': 93,\n",
       " '3.25.n': 94,\n",
       " '3.25.n20': 95,\n",
       " '3.25.n40': 96,\n",
       " '3.25.n50': 97,\n",
       " '3.25.n70': 98,\n",
       " '3.25.n80': 99,\n",
       " '3.27': 100,\n",
       " '3.28': 101,\n",
       " '3.29': 102,\n",
       " '3.30': 103,\n",
       " '3.31': 104,\n",
       " '3.32': 105,\n",
       " '3.33': 106,\n",
       " '3.34': 107,\n",
       " '3.35': 108,\n",
       " '3.4.n': 109,\n",
       " '3.4.n2': 110,\n",
       " '3.4.n5': 111,\n",
       " '3.4.n7': 112,\n",
       " '3.4.n8': 113,\n",
       " '3.6': 114,\n",
       " '3.7': 115,\n",
       " '4.1.1': 116,\n",
       " '4.1.2': 117,\n",
       " '4.1.3': 118,\n",
       " '4.1.4': 119,\n",
       " '4.1.5': 120,\n",
       " '4.1.6': 121,\n",
       " '4.2.1': 122,\n",
       " '4.2.2': 123,\n",
       " '4.2.3': 124,\n",
       " '4.3': 125,\n",
       " '4.5.1': 126,\n",
       " '4.8.2': 127,\n",
       " '4.8.3': 128,\n",
       " '5.11.1': 129,\n",
       " '5.12.1': 130,\n",
       " '5.14': 131,\n",
       " '5.15.1': 132,\n",
       " '5.15.2': 133,\n",
       " '5.15.3': 134,\n",
       " '5.15.5': 135,\n",
       " '5.15.7': 136,\n",
       " '5.16': 137,\n",
       " '5.17': 138,\n",
       " '5.18': 139,\n",
       " '5.19.1': 140,\n",
       " '5.20': 141,\n",
       " '5.21': 142,\n",
       " '5.22': 143,\n",
       " '5.3': 144,\n",
       " '5.4': 145,\n",
       " '5.5': 146,\n",
       " '5.6': 147,\n",
       " '5.7.1': 148,\n",
       " '5.7.2': 149,\n",
       " '5.8': 150,\n",
       " '6.15.1': 151,\n",
       " '6.15.2': 152,\n",
       " '6.15.3': 153,\n",
       " '6.16': 154,\n",
       " '6.2.n': 155,\n",
       " '6.2.n20': 156,\n",
       " '6.2.n40': 157,\n",
       " '6.2.n50': 158,\n",
       " '6.2.n60': 159,\n",
       " '6.2.n70': 160,\n",
       " '6.3.1': 161,\n",
       " '6.4': 162,\n",
       " '6.6': 163,\n",
       " '6.7': 164,\n",
       " '6.8.1': 165,\n",
       " '6.8.2': 166,\n",
       " '6.8.3': 167,\n",
       " '7.1': 168,\n",
       " '7.11': 169,\n",
       " '7.12': 170,\n",
       " '7.14': 171,\n",
       " '7.15': 172,\n",
       " '7.18': 173,\n",
       " '7.2': 174,\n",
       " '7.3': 175,\n",
       " '7.4': 176,\n",
       " '7.5': 177,\n",
       " '7.6': 178,\n",
       " '7.7': 179,\n",
       " '8.1.1': 180,\n",
       " '8.1.3': 181,\n",
       " '8.1.4': 182,\n",
       " '8.13': 183,\n",
       " '8.14': 184,\n",
       " '8.15': 185,\n",
       " '8.16': 186,\n",
       " '8.17': 187,\n",
       " '8.18': 188,\n",
       " '8.2.1': 189,\n",
       " '8.2.2': 190,\n",
       " '8.2.3': 191,\n",
       " '8.2.4': 192,\n",
       " '8.23': 193,\n",
       " '8.3.1': 194,\n",
       " '8.3.2': 195,\n",
       " '8.3.3': 196,\n",
       " '8.4.1': 197,\n",
       " '8.4.3': 198,\n",
       " '8.4.4': 199,\n",
       " '8.5.2': 200,\n",
       " '8.5.4': 201,\n",
       " '8.6.2': 202,\n",
       " '8.6.4': 203,\n",
       " '8.8': 204}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ResNet' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m      5\u001b[0m c \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(model, model2)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ResNet' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torch import nn\n",
    "model = torchvision.models.resnet50()\n",
    "model2 = nn.Linear(1000, 20)\n",
    "c = nn.Sequential(model, model2)\n",
    "print(c[0][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from albumentations import Compose, Rotate, RandomBrightnessContrast, GaussianBlur, Normalize, Resize, ToFloat\n",
    "import albumentations.pytorch as A\n",
    "\n",
    "# Определите константы\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "NETWORK_SIZE = (224, 224)  # Укажите размер сети, например, 224x224\n",
    "\n",
    "# Определите аугментации и преобразования\n",
    "augmentations = [\n",
    "    Rotate(limit=15, p=0.5),\n",
    "    RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.25),\n",
    "    GaussianBlur(p=0.3),\n",
    "]\n",
    "\n",
    "common_transforms = [\n",
    "    Resize(*NETWORK_SIZE),\n",
    "    ToFloat(max_value=255),\n",
    "    Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD, max_pixel_value=1.0),\n",
    "    A.transforms.ToTensorV2(),\n",
    "]\n",
    "\n",
    "# Определите полные трансформации\n",
    "MyFitTransform = Compose(augmentations + common_transforms)\n",
    "MyPredictTransform = Compose(common_transforms)\n",
    "\n",
    "# Создайте случайный тензор (изображение)\n",
    "random_image = (np.random.rand(256, 256, 3) * 255).astype(np.uint8)  # 256x256 случайное изображение с каналами RGB\n",
    "\n",
    "# Примените преобразования\n",
    "transformed_image = MyFitTransform(image=random_image)['image']\n",
    "\n",
    "# Проверка типа и формы результирующего тензора\n",
    "print(f\"Transformed image type: {type(transformed_image)}\")\n",
    "print(f\"Transformed image shape: {transformed_image.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import typing\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from collections import defaultdict\n",
    "\n",
    "import albumentations as A\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.metrics import recall_score\n",
    "import skimage\n",
    "import skimage.filters\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import torch\n",
    "import torchvision\n",
    "import tqdm\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# !Этих импортов достаточно для решения данного задания\n",
    "\n",
    "NETWORK_SIZE = (128, 128)\n",
    "CLASSES_CNT = 205\n",
    "BATCH_SIZE = 32\n",
    "SIMPLE_MAX_EPOCHS = 1\n",
    "SIMPLE_INTERNAL_FEATURES = 1024\n",
    "NUM_WORKERS = 11\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if DEVICE == torch.device(\"cuda:0\"):\n",
    "    torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "augmentations = [\n",
    "    A.Rotate(limit=15, p=0.5),\n",
    "    #A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.3),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.25),\n",
    "    A.GaussianBlur(p=0.3),\n",
    "    #A.HorizontalFlip(p=0.5),\n",
    "    #A.GaussNoise(var_limit=(5.0, 20.0), p=0.3),\n",
    "    #A.ElasticTransform(alpha=3, sigma=2, p=0.5),\n",
    "    #A.Perspective(p=0.25)\n",
    "]\n",
    "\n",
    "common_transforms = [\n",
    "    A.Resize(*NETWORK_SIZE),\n",
    "    A.ToFloat(max_value=255),\n",
    "    A.Normalize(max_pixel_value=1.0, mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "    A.pytorch.transforms.ToTensorV2(),\n",
    "]\n",
    "\n",
    "MyFitTransform = A.Compose(augmentations + common_transforms)\n",
    "MyPredictTransform = A.Compose(common_transforms)\n",
    "\n",
    "\n",
    "\n",
    "class DatasetRTSD(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Класс для чтения и хранения датасета.\n",
    "\n",
    "    :param root_folders: список путей до папок с данными\n",
    "    :param path_to_classes_json: путь до classes.json\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_folders: typing.List[str],\n",
    "        path_to_classes_json: str,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.classes, self.class_to_idx = self.get_classes(path_to_classes_json)\n",
    "        # список пар (путь до картинки, индекс класса)\n",
    "        \n",
    "        self.samples = []\n",
    "        for root in root_folders:\n",
    "            paths = glob.glob(f'{root}/**/*.png', recursive=True)\n",
    "            self.samples += [(path, self.class_to_idx[os.path.basename(os.path.dirname(path))]) for path in paths]\n",
    "        # cловарь из списков картинок для каждого класса, classes_to_samples[индекс класса] = [список чисел-позиций картинок в self.samples]\n",
    "        tmp = {}\n",
    "        for class_num in self.classes:\n",
    "            tmp[self.class_to_idx[class_num]] = []\n",
    "        for idx, pair in enumerate(self.samples):\n",
    "            class_num = pair[1]\n",
    "            tmp[class_num].append(idx)\n",
    "        self.classes_to_samples = tmp\n",
    "        # аугментации + нормализация + ToTensorV2\n",
    "        self.transform = MyFitTransform\n",
    "\n",
    "    def __getitem__(self, index: int) -> typing.Tuple[torch.Tensor, str, int]:\n",
    "        \"\"\"\n",
    "        Возвращает тройку: тензор с картинкой, путь до файла, номер класса файла (если нет разметки, то \"-1\").\n",
    "        \"\"\"\n",
    "        img_path, class_num = self.samples[index]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image=np.array(image))['image']\n",
    "        return image, img_path, class_num\n",
    "\n",
    "    @staticmethod\n",
    "    def get_classes(\n",
    "        path_to_classes_json,\n",
    "    ) -> typing.Tuple[typing.List[str], typing.Mapping[str, int]]:\n",
    "        \"\"\"\n",
    "        Считывает из classes.json информацию о классах.\n",
    "\n",
    "        :param path_to_classes_json: путь до classes.json\n",
    "        \"\"\"\n",
    "        with open(path_to_classes_json, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        ### YOUR CODE HERE - словарь, class_to_idx['название класса'] = индекс\n",
    "        class_to_idx = {class_name: data[class_name]['id'] for class_name in data}\n",
    "        ### YOUR CODE HERE - массив, classes[индекс] = 'название класса'\n",
    "        classes = [0] * 205\n",
    "        count = 0\n",
    "        for class_name in data:\n",
    "            count += 1\n",
    "            classes[data[class_name]['id']] = class_name\n",
    "        return classes[:count], class_to_idx\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Возвращает размер датасета (количество сэмплов).\n",
    "        \"\"\"\n",
    "        return len(self.samples)\n",
    "\n",
    "class TestData(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Класс для чтения и хранения тестового датасета.\n",
    "\n",
    "    :param root: путь до папки с картинками знаков\n",
    "    :param path_to_classes_json: путь до classes.json\n",
    "    :param annotations_file: путь до .csv-файла с аннотациями (опциональный)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        path_to_classes_json: str,\n",
    "        annotations_file: str = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.classes, self.class_to_idx = self.get_classes(path_to_classes_json)\n",
    "        # список путей до картинок\n",
    "        self.samples = [os.path.basename(path) for path in glob.glob(f'{root}/**/*.png', recursive=True)]\n",
    "        # преобразования: ресайз + нормализация + ToTensorV2\n",
    "        self.transform = MyPredictTransform\n",
    "        self.targets = None\n",
    "        if annotations_file is not None:\n",
    "            # словарь, targets[путь до картинки] = индекс класса\n",
    "            tmp = {}\n",
    "            with open(annotations_file, mode='r', encoding='utf-8') as file:\n",
    "                csv_reader = csv.reader(file)\n",
    "                next(csv_reader)\n",
    "                \n",
    "                for row in csv_reader:\n",
    "                    img_name = row[0] \n",
    "                    class_name = row[1]\n",
    "                    tmp[img_name] = self.class_to_idx[class_name]\n",
    "            self.targets = tmp\n",
    "\n",
    "    def __getitem__(self, index: int) -> typing.Tuple[torch.Tensor, str, int]:\n",
    "        \"\"\"\n",
    "        Возвращает тройку: тензор с картинкой, путь до файла, номер класса файла (если нет разметки, то \"-1\").\n",
    "        \"\"\"\n",
    "        img_name = self.samples[index]\n",
    "        image = Image.open(os.path.join(self.root, img_name)).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image=np.array(image))\n",
    "        return image['image'], img_name, self.targets[img_name] if self.targets else -1\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Возвращает размер датасета (количество сэмплов).\n",
    "        \"\"\"\n",
    "        return len(self.samples)\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_classes(\n",
    "        path_to_classes_json,\n",
    "    ) -> typing.Tuple[typing.List[str], typing.Mapping[str, int]]:\n",
    "        \"\"\"\n",
    "        Считывает из classes.json информацию о классах.\n",
    "\n",
    "        :param path_to_classes_json: путь до classes.json\n",
    "        \"\"\"\n",
    "        with open(path_to_classes_json, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        ### YOUR CODE HERE - словарь, class_to_idx['название класса'] = индекс\n",
    "        class_to_idx = {class_name: data[class_name]['id'] for class_name in data}\n",
    "        ### YOUR CODE HERE - массив, classes[индекс] = 'название класса'\n",
    "        classes = [0] * 205\n",
    "        count = 0\n",
    "        for class_name in data:\n",
    "            count += 1\n",
    "            classes[data[class_name]['id']] = class_name\n",
    "        return classes[:count], class_to_idx\n",
    "\n",
    "\n",
    "class CustomNetwork(L.LightningModule):\n",
    "    \"\"\"\n",
    "    Класс, реализующий нейросеть для классификации.\n",
    "\n",
    "    :param features_criterion: loss-функция на признаки, извлекаемые нейросетью перед классификацией (None когда нет такого лосса)\n",
    "    :param internal_features: внутреннее число признаков\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        features_criterion: (\n",
    "            typing.Callable[[torch.Tensor, torch.Tensor], torch.Tensor] | None\n",
    "        ) = None,\n",
    "        internal_features: int = SIMPLE_INTERNAL_FEATURES,\n",
    "        need_weights=False # ПОМЕНЯТЬ ПЕРЕД ЗАСЫЛКОЙ НА FALSE\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.features_criterion = features_criterion\n",
    "        self.model, self.classifier = self.get_model(internal_features, need_weights)\n",
    "        '''if not need_weights:\n",
    "            self.load_model()\n",
    "        '''\n",
    "    def get_model(self, internal_features, need_weights):\n",
    "        if need_weights:\n",
    "            model = torchvision.models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "        else:\n",
    "            model = torchvision.models.resnet50()\n",
    "        num_features = model.fc.in_features\n",
    "        model.fc = torch.nn.Linear(num_features, internal_features)\n",
    "        \n",
    "        classifier = torch.nn.Sequential(\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(internal_features, CLASSES_CNT),\n",
    "        )\n",
    "\n",
    "        '''for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        for param in classifier.parameters():\n",
    "            param.requires_grad = True'''\n",
    "            \n",
    "        return model, classifier\n",
    "    \n",
    "    def save_model(self):\n",
    "        torch.save(self.state_dict(), 'simple_model.pth')\n",
    "        #full_model = torch.nn.Sequential(torch.nn.ModuleList([self.model, self.classifier]))\n",
    "        #torch.save(full_model.state_dict(), 'simple_model.pth')\n",
    "\n",
    "    def load_model(self, path_to_model='simple_model.pth'):\n",
    "        self.load_state_dict(torch.load(path_to_model, map_location=\"cpu\", weights_only=True))\n",
    "        \n",
    "    '''def load_model(self, path_to_model='simple_model.pth'):\n",
    "        full_model = torch.nn.Sequential(torch.nn.ModuleList([self.model, self.classifier]))\n",
    "        full_model.load_state_dict(torch.load(path_to_model, map_location=\"cpu\", weights_only=True))\n",
    "        self.model = full_model[0][0]\n",
    "        self.classifier = full_model[0][1]'''\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> typing.Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Функция для прогона данных через нейронную сеть.\n",
    "        Возвращает два тензора: внутреннее представление и логиты после слоя-классификатора.\n",
    "        \"\"\"\n",
    "        features = self.model(x)\n",
    "        logits = self.classifier(features)\n",
    "        return features, logits\n",
    "\n",
    "    def predict(self, x: torch.Tensor) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Функция для предсказания классов-ответов. Возвращает np-массив с индексами классов.\n",
    "\n",
    "        :param x: батч с картинками\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            _, logits = self(x)\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "        return predictions.cpu().numpy()\n",
    "\n",
    "    def print_batch(batch):\n",
    "        for image, _, landmark in batch:\n",
    "        image = (image - image.min()) / (image.max() - image.min())\n",
    "\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(image.numpy().transpose((1, 2, 0)))\n",
    "        plt.label = landmark\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Один шаг обучения, который включает расчет лосса.\n",
    "        \"\"\"\n",
    "        x, _, y = batch\n",
    "\n",
    "        features, logits = self(x)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "        \n",
    "        if self.features_criterion is not None:\n",
    "            features_loss = self.features_criterion(features, y)\n",
    "            loss += features_loss\n",
    "\n",
    "        self.running_train_loss += loss.item()\n",
    "        self.train_batch_count += 1\n",
    "\n",
    "        running_avg_loss = self.running_train_loss / self.train_batch_count\n",
    "        self.log(\"running_train_loss\", running_avg_loss, on_step=True, prog_bar=True)\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_start(self):\n",
    "        \"\"\"\n",
    "        Сброс значений накопленного лосса и количества батчей в начале каждой эпохи.\n",
    "        \"\"\"\n",
    "        self.running_train_loss = 0.0\n",
    "        self.train_batch_count = 0\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        \"\"\"\n",
    "        Шаг валидации. Вычисляет и логирует лосс и метрики.\n",
    "        \"\"\"\n",
    "        x, _, y = batch\n",
    "        features, logits = self(x)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        \n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "\n",
    "    '''def training_step(self, batch):\n",
    "        \"\"\"\n",
    "        Один шаг обучения, который включает расчет лосса.\n",
    "        \"\"\"\n",
    "        x, _, y = batch\n",
    "        features, logits = self(x)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "        \n",
    "        if self.features_criterion is not None:\n",
    "            features_loss = self.features_criterion(features, y)\n",
    "            loss += features_loss\n",
    "        \n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    '''\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Настройка оптимизаторов.\n",
    "        \"\"\"\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "def train_simple_classifier() -> torch.nn.Module:\n",
    "    \"\"\"\n",
    "    Функция для обучения простого классификатора с валидацией.\n",
    "    \"\"\"\n",
    "    full_dataset = DatasetRTSD(\n",
    "        root_folders=[\"./cropped-train/\"],\n",
    "        path_to_classes_json=\"./classes.json\"\n",
    "    )\n",
    "\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "    model = CustomNetwork()\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=SIMPLE_MAX_EPOCHS,\n",
    "        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "        devices=1\n",
    "    )\n",
    "    \n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    model.save_model()\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def apply_classifier(\n",
    "    model: CustomNetwork,\n",
    "    test_folder: str,\n",
    "    path_to_classes_json: str,\n",
    ") -> typing.List[typing.Mapping[str, typing.Any]]:\n",
    "    \"\"\"\n",
    "    Функция, которая применяет модель и получает её предсказания.\n",
    "\n",
    "    :param model: модель, которую нужно протестировать\n",
    "    :param test_folder: путь до папки с тестовыми данными\n",
    "    :param path_to_classes_json: путь до файла с информацией о классах classes.json\n",
    "    \"\"\"\n",
    "    test_dataset = TestData(\n",
    "        root=test_folder,\n",
    "        path_to_classes_json=path_to_classes_json,\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "    results = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, img_names, annotations in test_loader:\n",
    "            #images = images.to(DEVICE)\n",
    "            predictions = model.predict(images)\n",
    "            \n",
    "            for img_name, class_idx, annotation in zip(img_names, predictions, annotations):\n",
    "                class_name = test_dataset.classes[class_idx]\n",
    "                results.append({\"filename\": img_name, \"class\": class_name, \"gt\": annotation})\n",
    "    return results\n",
    "\n",
    "def calc_metric(y_true, y_pred):\n",
    "    ok_cnt = 0\n",
    "    all_cnt = 0\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        all_cnt += 1\n",
    "        if t == p:\n",
    "            ok_cnt += 1\n",
    "    return ok_cnt / max(1, all_cnt)\n",
    "\n",
    "def test_classifier(\n",
    "    model: CustomNetwork,\n",
    "    test_folder: str = \"./smalltest/\",\n",
    "    annotations_file: str = \"./smalltest_annotations.csv\",\n",
    "    path_to_classes_json:str = \"./classes.json\",\n",
    ") -> typing.Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Функция для тестирования качества модели.\n",
    "    Возвращает точность на всех знаках, Recall на редких знаках и Recall на частых знаках.\n",
    "\n",
    "    :param model: модель, которую нужно протестировать\n",
    "    :param test_folder: путь до папки с тестовыми данными\n",
    "    :param annotations_file: путь до .csv-файла с аннотациями\n",
    "    \"\"\"\n",
    "    # Используем apply_classifier для получения предсказаний\n",
    "    predictions = apply_classifier(model, test_folder, path_to_classes_json)\n",
    "    with open(path_to_classes_json, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "            \n",
    "    targets = {}\n",
    "    with open(annotations_file, mode='r', encoding='utf-8') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            img_name = row[0]\n",
    "            class_name = row[1]\n",
    "            targets[img_name] = class_name\n",
    "\n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "    all_types = []\n",
    "    for pred in predictions:\n",
    "        img_name = pred['filename']\n",
    "        predicted_class = pred['class']\n",
    "        #gt = pred['gt']\n",
    "        if img_name in targets:\n",
    "            true_class = targets[img_name]\n",
    "            all_preds.append(predicted_class)\n",
    "            all_trues.append(true_class)\n",
    "            all_types.append(data[true_class]['type'])\n",
    "\n",
    "    y_pred_rare = []\n",
    "    y_pred_freq = []\n",
    "    y_true_rare = []\n",
    "    y_true_freq = []\n",
    "    for i in range(len(all_types)):\n",
    "        if all_types[i] == 'freq':\n",
    "            y_pred_freq.append(all_preds[i])\n",
    "            y_true_freq.append(all_trues[i])\n",
    "        else:\n",
    "            y_pred_rare.append(all_preds[i])\n",
    "            y_true_rare.append(all_trues[i])\n",
    "\n",
    "    total_metric = calc_metric(all_trues, all_preds)\n",
    "    rare_metric = calc_metric(y_true_rare, y_pred_rare)\n",
    "    freq_metric = calc_metric(y_true_freq, y_pred_freq)\n",
    "\n",
    "    return total_metric, rare_metric, freq_metric\n",
    "\n",
    "\n",
    "\n",
    "class SignGenerator(object):\n",
    "    \"\"\"\n",
    "    Класс для генерации синтетических данных.\n",
    "\n",
    "    :param background_path: путь до папки с изображениями фона\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, background_path: str) -> None:\n",
    "        super().__init__()\n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "    ### Для каждого из необходимых преобразований над иконками/картинками,\n",
    "    ### напишите вспомогательную функцию приблизительно следующего вида:\n",
    "    ###\n",
    "    ### @staticmethod\n",
    "    ### def discombobulate_icon(icon: np.ndarray) -> np.ndarray:\n",
    "    ###     ### YOUR CODE HERE\n",
    "    ###     return ...\n",
    "    ###\n",
    "    ### Постарайтесь не использовать готовые библиотечные функции для\n",
    "    ### аугментаций и преобразования картинок, а реализовать их\n",
    "    ### \"из первых принципов\" на numpy\n",
    "\n",
    "    def get_sample(self, icon: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Функция, встраивающая иконку на случайное изображение фона.\n",
    "\n",
    "        :param icon: Массив с изображением иконки\n",
    "        \"\"\"\n",
    "        ### YOUR CODE HERE\n",
    "        icon = ...\n",
    "        ### YOUR CODE HERE - случайное изображение фона\n",
    "        bg = ...\n",
    "        return  ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "def generate_one_icon(args: typing.Tuple[str, str, str, int]) -> None:\n",
    "    \"\"\"\n",
    "    Функция, генерирующая синтетические данные для одного класса.\n",
    "\n",
    "    :param args: Это список параметров: [путь до файла с иконкой, путь до выходной папки, путь до папки с фонами, число примеров каждого класса]\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "def generate_all_data(\n",
    "    output_folder: str,\n",
    "    icons_path: str,\n",
    "    background_path: str,\n",
    "    samples_per_class: int = 1000,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Функция, генерирующая синтетические данные.\n",
    "    Эта функция запускает пул параллельно работающих процессов, каждый из которых будет генерировать иконку своего типа.\n",
    "    Это необходимо, так как процесс генерации очень долгий.\n",
    "    Каждый процесс работает в функции generate_one_icon.\n",
    "\n",
    "    :param output_folder: Путь до выходной директории\n",
    "    :param icons_path: Путь до директории с иконками\n",
    "    :param background_path: Путь до директории с картинками фона\n",
    "    :param samples_per_class: Количество примеров каждого класса, которые надо сгенерировать\n",
    "    \"\"\"\n",
    "    shutil.rmtree(output_folder, ignore_errors=True)\n",
    "    with ProcessPoolExecutor(8) as executor:\n",
    "        params = [\n",
    "            [\n",
    "                os.path.join(icons_path, icon_file),\n",
    "                output_folder,\n",
    "                background_path,\n",
    "                samples_per_class,\n",
    "            ]\n",
    "            for icon_file in os.listdir(icons_path)\n",
    "        ]\n",
    "        list(tqdm.tqdm(executor.map(generate_one_icon, params)))\n",
    "\n",
    "\n",
    "def train_synt_classifier() -> torch.nn.Module:\n",
    "    \"\"\"\n",
    "    Функция для обучения простого классификатора на смеси исходных и ситетических данных.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    return model\n",
    "\n",
    "\n",
    "class FeaturesLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Класс для вычисления loss-функции на признаки предпоследнего слоя нейросети.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin: float) -> None:\n",
    "        super().__init__()\n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "    def forward(self, outputs: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Функция, вычисляющая loss-функцию на признаки предпоследнего слоя нейросети.\n",
    "\n",
    "        :param outputs: Признаки с предпоследнего слоя нейросети\n",
    "        :param labels: Реальные метки объектов\n",
    "        \"\"\"\n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "class CustomBatchSampler(torch.utils.data.sampler.Sampler[typing.List[int]]):\n",
    "    \"\"\"\n",
    "    Класс для семплирования батчей с контролируемым числом классов и примеров каждого класса.\n",
    "\n",
    "    :param data_source: Это датасет RTSD\n",
    "    :param elems_per_class: Число элементов каждого класса\n",
    "    :param classes_per_batch: Количество различных классов в одном батче\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_source: DatasetRTSD,\n",
    "        elems_per_class: int,\n",
    "        classes_per_batch: int,\n",
    "    ) -> None:\n",
    "        ### YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Функция, которая будет генерировать список индексов элементов в батче.\n",
    "        \"\"\"\n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "    def __len__(self) -> None:\n",
    "        \"\"\"\n",
    "        Возвращает общее количество батчей.\n",
    "        \"\"\"\n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "def train_better_model() -> torch.nn.Module:\n",
    "    \"\"\"\n",
    "    Функция для обучения классификатора на смеси исходных и ситетических данных с новым лоссом на признаки.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    return model\n",
    "\n",
    "\n",
    "class ModelWithHead(CustomNetwork):\n",
    "    \"\"\"\n",
    "    Класс, реализующий модель с головой из kNN.\n",
    "\n",
    "    :param n_neighbors: Количество соседей в методе ближайших соседей\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_neighbors: int) -> None:\n",
    "        super().__init__()\n",
    "        self.eval()\n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "    def load_nn(self, nn_weights_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Функция, загружающая веса обученной нейросети.\n",
    "\n",
    "        :param nn_weights_path: Это путь до весов обученной нейросети с улучшенными признаками на предпоследнем слое\n",
    "        \"\"\"\n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "    def load_head(self, knn_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Функция, загружающая веса kNN (с помощью pickle).\n",
    "\n",
    "        :param knn_path: Путь, откуда надо прочитать веса kNN\n",
    "        \"\"\"\n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "    def save_head(self, knn_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Функция, сохраняющая веса kNN (с помощью pickle).\n",
    "\n",
    "        :param knn_path: Путь, куда надо сохранить веса kNN\n",
    "        \"\"\"\n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "    def train_head(self, indexloader: torch.utils.data.DataLoader) -> None:\n",
    "        \"\"\"\n",
    "        Функция, обучающая голову kNN.\n",
    "\n",
    "        :param indexloader: Загрузчик данных для обучения kNN\n",
    "        \"\"\"\n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "    def predict(self, imgs: torch.Tensor) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Функция для предсказания классов-ответов. Возвращает np-массив с индексами классов.\n",
    "\n",
    "        :param imgs: батч с картинками\n",
    "        \"\"\"\n",
    "        ### YOUR CODE HERE - предсказание нейросетевой модели\n",
    "        features, model_pred = ...\n",
    "        features = features / np.linalg.norm(features, axis=1)[:, None]\n",
    "        ### YOUR CODE HERE - предсказание kNN на features\n",
    "        knn_pred = ...\n",
    "        return knn_pred\n",
    "\n",
    "\n",
    "class IndexSampler(torch.utils.data.sampler.Sampler[int]):\n",
    "    \"\"\"\n",
    "    Класс для семплирования батчей с картинками индекса.\n",
    "\n",
    "    :param data_source: Это датасет RTSD с синтетическими примерами\n",
    "    :param examples_per_class: Число элементов каждого класса, которые должны попасть в индекс\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_source: DatasetRTSD, examples_per_class: int) -> None:\n",
    "        ### YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Функция, которая будет генерировать список индексов элементов в батче.\n",
    "        \"\"\"\n",
    "        return  ### YOUR CODE HERE\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Возвращает общее количество индексов.\n",
    "        \"\"\"\n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "def train_head(nn_weights_path: str, examples_per_class: int = 20) -> torch.nn.Module:\n",
    "    \"\"\"\n",
    "    Функция для обучения kNN-головы классификатора.\n",
    "\n",
    "    :param nn_weights_path: Это путь до весов обученной нейросети с улучшенными признаками на предпоследнем слое\n",
    "    :param examples_per_class: Число элементов каждого класса, которые должны попасть в индекс\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # The following code won't be run in the test system, but you can run it\n",
    "    # on your local computer with `python -m rare_traffic_sign_solution`.\n",
    "\n",
    "    # Feel free to put here any code that you used while\n",
    "    # debugging, training and testing your solution.\n",
    "    pass\n",
    "    train_simple_classifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
