{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from os.path import join\n",
    "from run import read_csv, save_csv\n",
    "import random\n",
    "import glob\n",
    "import albumentations.pytorch.transforms\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torchmetrics\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchmetrics\n",
    "import matplotlib.pyplot as plt \n",
    "from os.path import basename\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using the GPU üòä\")\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"Using the CPU üòû\")\n",
    "        return torch.device(\"cpu\")\n",
    "    \n",
    "\n",
    "NETWORK_SIZE = (480, 480)\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 0\n",
    "NUM_CLASSES = 50\n",
    "BASE_LR = 1e-3\n",
    "MAX_EPOCHS = 50\n",
    "\n",
    "path_train = './tests/00_test_img_input/train/'\n",
    "path_experiment = './experiment/'\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "augmentations = [\n",
    "    A.Rotate(limit=45, p=0.5),\n",
    "    #A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.3),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.25),\n",
    "    A.GaussianBlur(p=0.3),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    #A.GaussNoise(var_limit=(5.0, 20.0), p=0.3),\n",
    "    #A.ElasticTransform(alpha=3, sigma=2, p=0.5),\n",
    "    A.Perspective(p=0.25)\n",
    "    #A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=20, p=0.3),\n",
    "    #A.CoarseDropout(max_holes=8, max_height=8, max_width=8, p=0.5),\n",
    "]\n",
    "\n",
    "common_transforms = [\n",
    "    A.Resize(*NETWORK_SIZE),\n",
    "    A.ToFloat(max_value=255),\n",
    "    A.Normalize(max_pixel_value=1.0, mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "    A.pytorch.transforms.ToTensorV2(),\n",
    "]\n",
    "\n",
    "MyFitTransform = A.Compose(augmentations + common_transforms)\n",
    "MyPredictTransform = A.Compose(common_transforms)\n",
    "\n",
    "\n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, img_dir, data, stage, transform=None):\n",
    "        self._image_dir = img_dir\n",
    "        self._data = data\n",
    "        self._stage = stage\n",
    "\n",
    "        if not transform:\n",
    "            if stage in ['train', 'fit']:\n",
    "                self._transform = MyFitTransform\n",
    "            elif stage in ['validate', 'test', 'predict']:\n",
    "                self._transform = MyPredictTransform\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self._stage in ['fit', 'train', 'validate', 'test']:\n",
    "            img_path, label = self._data[idx]\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            if self._transform:\n",
    "                image = self._transform(image=np.array(image))\n",
    "            return image['image'], label\n",
    "        elif self._stage == 'predict':\n",
    "            img_path = self._data[idx]\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            if self._transform:\n",
    "                image = self._transform(image=np.array(image))\n",
    "            return image['image']\n",
    "\n",
    "class ImgDataModule(L.LightningDataModule):\n",
    "    def __init__(\n",
    "        self, \n",
    "        data_dir = '', \n",
    "        img_dir = '',\n",
    "        gt_dict = None, \n",
    "        batch_size: int = BATCH_SIZE, \n",
    "        num_workers: int = NUM_WORKERS,\n",
    "        split_seed=42,\n",
    "        train_share = 0.7,\n",
    "        valid_share = 0.2,\n",
    "        test_share = 0.1,\n",
    "        transform=common_transforms,\n",
    "        aug_transform=augmentations,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._data_dir = data_dir\n",
    "        self._img_dir = img_dir\n",
    "        self._gt_dict = gt_dict\n",
    "        self._batch_size = batch_size\n",
    "        self._num_workers = num_workers\n",
    "        self._split_seed = split_seed\n",
    "        self._train_share = train_share\n",
    "        self._valid_share = valid_share\n",
    "        self._test_share = test_share\n",
    "        self._transform = transform\n",
    "        self._aug_transform = aug_transform\n",
    "        \n",
    "    def setup(self, stage):\n",
    "        if self._data_dir != '':\n",
    "            img_dir = join(self._data_dir, 'images')\n",
    "        elif self._data_dir == '' and self._img_dir != '':\n",
    "            img_dir = self._img_dir\n",
    "        paths = sorted(glob.glob(f\"{img_dir}/*\"))\n",
    "        \n",
    "        if stage in ['fit', 'train', 'validate', 'test']:\n",
    "            if self._data_dir != '':\n",
    "                gt_dict = read_csv(join(self._data_dir, 'gt.csv'))\n",
    "            elif self._data_dir == '' and self._gt_dict is not None:\n",
    "                gt_dict = self._gt_dict\n",
    "            \n",
    "            labels = [gt_dict[path.split('/')[-1]] for path in paths]\n",
    "            \n",
    "            path_train, path_test, label_train, label_test = train_test_split(paths, labels, test_size=(self._test_share + self._valid_share), random_state=self._split_seed, stratify=labels)\n",
    "            path_val, path_test, label_val, label_test = train_test_split(path_test, label_test, test_size=(self._test_share / self._valid_share), random_state=self._split_seed, stratify=label_test)\n",
    "            \n",
    "            self._train_data = list(zip(path_train, label_train))\n",
    "            self._val_data = list(zip(path_val, label_val))\n",
    "            self._test_data = list(zip(path_test, label_test))\n",
    "            #print(Counter(labels))\n",
    "            #print(Counter(label_train))\n",
    "            #print(Counter(label_val))\n",
    "            #print(Counter(label_test))\n",
    "\n",
    "        elif stage == 'predict':\n",
    "            self._pred_data = paths\n",
    "            \n",
    "        else:\n",
    "            raise RuntimeError(f\"Invalid stage: {stage!r}\")\n",
    "        \n",
    "        self._img_dir = img_dir\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        ds = ImgDataset(img_dir=self._img_dir, data=self._train_data, stage='train')\n",
    "        return DataLoader(ds, batch_size=self._batch_size, shuffle=True, drop_last=True, num_workers=self._num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        ds = ImgDataset(img_dir=self._img_dir, data=self._val_data, stage='validate')\n",
    "        return DataLoader(ds, batch_size=self._batch_size, shuffle=False, drop_last=False, num_workers=self._num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        ds = ImgDataset(img_dir=self._img_dir, data=self._test_data, stage='test')\n",
    "        return DataLoader(ds, batch_size=self._batch_size, shuffle=False, drop_last=False, num_workers=self._num_workers)\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        ds = ImgDataset(img_dir=self._img_dir, data=self._pred_data, stage='predict')\n",
    "        return DataLoader(ds, batch_size=self._batch_size, shuffle=False, drop_last=False, num_workers=self._num_workers)\n",
    "    \n",
    "class LightningBirdClassifier(L.LightningModule):\n",
    "\n",
    "    def __init__(self, *, transfer=False, lr=BASE_LR, model_path='./birds_model.pt', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.lr = lr\n",
    "        self.transfer = transfer\n",
    "        self.num_classes = 50\n",
    "        self.model = self.get_model()\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.accuracy = torchmetrics.classification.Accuracy(\n",
    "            task=\"multiclass\",\n",
    "            num_classes=self.num_classes,\n",
    "        )\n",
    "        self.model_path = model_path\n",
    "\n",
    "    def get_model(self):\n",
    "        if not self.transfer:\n",
    "            model = models.efficientnet_v2_m(weights=\"IMAGENET1K_V1\")\n",
    "            num_features = model.classifier[1].in_features\n",
    "            model.classifier[1] = nn.Sequential(\n",
    "                nn.Dropout(p=0.5),\n",
    "                nn.Linear(num_features, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, self.num_classes),\n",
    "                nn.Softmax(dim=1)\n",
    "            )\n",
    "            nn.Linear(num_features, self.num_classes)\n",
    "            \n",
    "            \n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "            \n",
    "            for param in model.classifier[1].parameters():\n",
    "                param.requires_grad = True\n",
    "            return model\n",
    "        else:\n",
    "            self.load_model()\n",
    "            return self.model\n",
    "    \n",
    "    def save_model(self):\n",
    "        torch.save(self.model, 'birds_model.pt')\n",
    "\n",
    "    def load_model(self):\n",
    "        self.model = torch.load(self.model_path, map_location=get_device())\n",
    "        self.model.eval()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "            optimizer, step_size=10, gamma=0.1\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"valid_loss\",  # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–Ω–∞—á–µ–Ω–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "                \"interval\": \"epoch\",      # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–∞–∂–¥—É—é —ç–ø–æ—Ö—É\n",
    "                \"frequency\": 1            # –ß–∞—Å—Ç–æ—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        return self._step(batch, \"train\")\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        return self._step(batch, \"valid\")\n",
    "\n",
    "    def _step(self, batch, kind):\n",
    "        x, y = batch\n",
    "        p = self.model(x)\n",
    "        loss = self.loss_fn(p, y)\n",
    "        acc = self.accuracy(p.argmax(dim=-1), y)\n",
    "\n",
    "        return self._log_metrics(loss, acc, kind)\n",
    "\n",
    "    def _log_metrics(self, loss, acc, kind):\n",
    "        metrics = {}\n",
    "        if loss is not None:\n",
    "            metrics[f\"{kind}_loss\"] = loss\n",
    "        if acc is not None:\n",
    "            metrics[f\"{kind}_acc\"] = acc\n",
    "        self.log_dict(\n",
    "            metrics,\n",
    "            prog_bar=True,\n",
    "            logger=True,\n",
    "            on_step=(kind == \"train\"),\n",
    "            on_epoch=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    experiment_path,\n",
    "    data_module,\n",
    "    model,\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    **trainer_kwargs,\n",
    "):\n",
    "\n",
    "    callbacks = [\n",
    "        L.pytorch.callbacks.TQDMProgressBar(leave=True),\n",
    "        L.pytorch.callbacks.LearningRateMonitor(),\n",
    "        L.pytorch.callbacks.ModelCheckpoint(\n",
    "            filename=\"{epoch}-{valid_acc:.3f}\",\n",
    "            monitor=\"valid_acc\",\n",
    "            mode=\"max\",\n",
    "            save_top_k=3,\n",
    "            save_last=True,\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        callbacks=callbacks,\n",
    "        max_epochs=max_epochs,\n",
    "        default_root_dir=experiment_path,\n",
    "        **trainer_kwargs,\n",
    "    )\n",
    "    \n",
    "    data_module.setup(stage='fit')\n",
    "    trainer.fit(model, train_dataloaders=data_module.train_dataloader(), val_dataloaders=data_module.val_dataloader())\n",
    "\n",
    "    \n",
    "def train_classifier(train_gt, train_img_dir, fast_train=False, num_epochs=MAX_EPOCHS):\n",
    "    if fast_train:\n",
    "        data_module = ImgDataModule(\n",
    "            img_dir=train_img_dir,\n",
    "            gt_dict=train_gt,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            train_share=0.2,\n",
    "            valid_share=0.2,\n",
    "            test_share=0.6\n",
    "        )\n",
    "        \n",
    "        torch.set_float32_matmul_precision('medium')\n",
    "        \n",
    "        model = LightningBirdClassifier(\n",
    "            transfer=True,\n",
    "            lr=BASE_LR,\n",
    "        )\n",
    "        \n",
    "        train_model(\n",
    "            experiment_path=path_experiment, #–£–ë–†–ê–¢–¨ –î–û –ó–ê–°–´–õ–ê –í –°–ò–°–¢–ï–ú–£–£–£–£ –∏–ª–∏ –Ω–µ—Ç—Ç...\n",
    "            data_module=data_module,\n",
    "            model=model,\n",
    "            max_epochs=num_epochs,      \n",
    "            accelerator=\"cpu\" if get_device() == torch.device('cpu') else 'gpu',\n",
    "            devices=1,\n",
    "            precision=16,\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        data_module = ImgDataModule(\n",
    "            img_dir=train_img_dir,\n",
    "            gt_dict=train_gt,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            train_share=0.8,\n",
    "            valid_share=0.199,\n",
    "            test_share=0.001 # –µ—Å–ª–∏ –Ω—É–∂–Ω–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "        )\n",
    "        \n",
    "        #torch.set_float32_matmul_precision('medium')\n",
    "        \n",
    "        model = LightningBirdClassifier(\n",
    "            transfer=False,\n",
    "            lr=BASE_LR,\n",
    "        )\n",
    "        \n",
    "        train_model(\n",
    "            experiment_path=path_experiment, #–£–ë–†–ê–¢–¨ –î–û –ó–ê–°–´–õ–ê –í –°–ò–°–¢–ï–ú–£–£–£–£ –∏–ª–∏ –Ω–µ—Ç—Ç...\n",
    "            data_module=data_module,\n",
    "            model=model,\n",
    "            max_epochs=num_epochs,      \n",
    "            accelerator=\"cpu\" if get_device() == torch.device('cpu') else 'gpu',\n",
    "            devices=1,\n",
    "            precision=16,\n",
    "        )\n",
    "        model.save_model()\n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "def classify(model_path, test_img_dir):\n",
    "    data_module = ImgDataModule(\n",
    "            img_dir=test_img_dir,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            train_share=0.7,\n",
    "            valid_share=0.2,\n",
    "            test_share=0.1 # –µ—Å–ª–∏ –Ω—É–∂–Ω–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "        )\n",
    "    \n",
    "    model = LightningBirdClassifier(\n",
    "            transfer=True,\n",
    "            lr=BASE_LR,\n",
    "            model_path=model_path,\n",
    "        )\n",
    "    \n",
    "    trainer = L.Trainer()\n",
    " \n",
    "    predictions_batches = trainer.predict(model, data_module.predict_dataloader())\n",
    "    \n",
    "    results = {}\n",
    "    image_paths = data_module._pred_data\n",
    "\n",
    "    predictions = torch.cat([torch.argmax(batch, dim=1) for batch in predictions_batches]).cpu().numpy()\n",
    "\n",
    "    results = {\n",
    "        basename(image_path): int(pred_class)\n",
    "        for image_path, pred_class in zip(image_paths, predictions)\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_image(dl, batches=1):\n",
    "    count_bat = 0\n",
    "    for batch in dl:\n",
    "        images, labels = batch\n",
    "        #print(images.shape)\n",
    "        for i in range(images.shape[0]):\n",
    "            image, label = images[i], labels[i]\n",
    "            image = (image - image.min()) / (image.max() - image.min())\n",
    "\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(image.numpy().transpose((1, 2, 0)))\n",
    "            plt.title(label=label)\n",
    "\n",
    "            plt.show()\n",
    "        count_bat += 1\n",
    "        if count_bat == batches:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module1 = ImgDataModule(\n",
    "    data_dir=path_train, \n",
    "    batch_size=16,\n",
    "    train_share=0.7,\n",
    "    valid_share=0.2,\n",
    "    test_share=0.1  # –µ—Å–ª–∏ –Ω—É–∂–Ω–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    ")\n",
    "'''data_module1.setup(stage='train')\n",
    "train_loader = data_module1.train_dataloader()\n",
    "print_image(train_loader, 10)\n",
    "\n",
    "val_loader = data_module1.val_dataloader()\n",
    "print_image(val_loader)\n",
    "\n",
    "data_module1.setup(stage='validate')\n",
    "val_loader = data_module1.val_dataloader()\n",
    "print_image(val_loader)\n",
    "\n",
    "data_module1.setup(stage='test')\n",
    "test_loader = data_module1.test_dataloader()\n",
    "print_image(test_loader)\n",
    "\n",
    "data_module1.setup(stage='predict')\n",
    "pred_loader = data_module1.predict_dataloader()\n",
    "print_image(pred_loader)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightningBirdClassifier(\n",
    "            transfer=False,\n",
    "            lr=BASE_LR,\n",
    "        )\n",
    "model.get_model()\n",
    "model.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_test(data_dir, output_dir):\n",
    "    from classification import train_classifier, classify\n",
    "    from os.path import abspath, dirname, join\n",
    "\n",
    "    train_dir = join(data_dir, 'train')\n",
    "    test_dir = join(data_dir, 'test')\n",
    "\n",
    "    train_gt = read_csv(join(train_dir, 'gt.csv'))\n",
    "    train_img_dir = join(train_dir, 'images')\n",
    "\n",
    "    model = train_classifier(train_gt, train_img_dir, fast_train=False)\n",
    "    MODEL = model\n",
    "    \n",
    "    code_dir = './'\n",
    "    model_path = join(code_dir, 'birds_model.pt')\n",
    "    test_img_dir = join(test_dir, 'images')\n",
    "    img_classes = classify(model_path, test_img_dir)\n",
    "    save_csv(img_classes, join(output_dir, 'output.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/Documents/programing/Python/CV/cv_env/lib/python3.12/site-packages/lightning/fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "/Users/user/Documents/programing/Python/CV/cv_env/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py:512: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name     | Type               | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | model    | EfficientNet       | 53.2 M | train\n",
      "1 | loss_fn  | CrossEntropyLoss   | 0      | train\n",
      "2 | accuracy | MulticlassAccuracy | 0      | train\n",
      "--------------------------------------------------------\n",
      "340 K     Trainable params\n",
      "52.9 M    Non-trainable params\n",
      "53.2 M    Total params\n",
      "212.797   Total estimated model params size (MB)\n",
      "1029      Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the CPU üòû\n",
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/Documents/programing/Python/CV/cv_env/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from re import sub\n",
    "from os import makedirs\n",
    "\n",
    "for input_dir in sorted(glob.glob(join('./tests/', '[0-9][0-9]_*_input'))):\n",
    "    output_dir = sub('input$', 'check', input_dir)\n",
    "    run_output_dir = join(output_dir, 'output')\n",
    "    makedirs(run_output_dir, exist_ok=True)\n",
    "    run_single_test(input_dir, run_output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
